
* ```find_all():```
```
å¸¸ç”¨é€šè¿‡find_all()æ–¹æ³•æ¥æŸ¥æ‰¾æ ‡ç­¾å…ƒç´ ï¼š<>.find_all(name, attrs, recursive, string, **kwargs) ï¼Œè¿”å›ä¸€ä¸ªåˆ—è¡¨ç±»å‹ï¼ˆç”¨len()æŸ¥çœ‹åˆ—è¡¨ä¸­å…ƒç´ ä¸ªæ•°ï¼‰ï¼Œå­˜å‚¨æŸ¥æ‰¾çš„ç»“æœ 
â€¢ nameï¼šå¯¹æ ‡ç­¾åç§°çš„æ£€ç´¢å­—ç¬¦ä¸²
â€¢ attrsï¼šå¯¹æ ‡ç­¾å±æ€§å€¼çš„æ£€ç´¢å­—ç¬¦ä¸²ï¼Œå¯æ ‡æ³¨å±æ€§æ£€ç´¢
â€¢ recursiveï¼šæ˜¯å¦å¯¹å­å­™å…¨éƒ¨æ£€ç´¢ï¼Œé»˜è®¤True
â€¢ stringï¼š<>â€¦</>ä¸­å­—ç¬¦ä¸²åŒºåŸŸçš„æ£€ç´¢å­—ç¬¦ä¸² 
```

* è§£é‡Š```for link in i[1:59:2]:```
```

def parsehtml(namelist,urllist,html):
    url='http://www.en8848.com.cn/'
    soup=BeautifulSoup(html,'html.parser')
    t=soup.find(attrs={'class':'ch_content'})
    #print(t)
    i=t.find_all('a')
    # print(i)
    # print(len(i))
    """å¯ä»¥å…ˆè¿›è¡Œå¦‚æ­¤æœç´¢ï¼Œå†æ ¹æ®æ˜¾ç¤ºæ‰€å¾—ï¼Œè¿›è¡Œç­›é€‰ï¼Œ
    for link in i:
        print(link.get('href'))
        print(link.get('title'))
    """
    for link in i[1:59:2]:
       urllist.append(url+link.get('href'))
       namelist.append(link.get('title'))
```
![](https://github.com/BinGYiZhanG/Python_/blob/master/Reptile/Images/py19123623.jpg)

* 
![](https://github.com/BinGYiZhanG/Python_/blob/master/Reptile/Images/py19123625.jpg)
* è§£é‡Š```t=soup.find(attrs={'class':'jxa_content','id':'articlebody'})```
```
# ç”ŸæˆçŸ­æ–‡å†…å®¹
def parsehtml2(html):
    text=[]
    soup=BeautifulSoup(html,'html.parser')
    t=soup.find(attrs={'class':'jxa_content','id':'articlebody'})
    for i in t.findAll('p'):
        text.append(i.text)
    #print(text)
    return "\n".join(text)
```
![](https://github.com/BinGYiZhanG/Python_/blob/master/Reptile/Images/py19123626.jpg)



* ä»£ç 

```
import requests
from bs4 import BeautifulSoup
import smtplib
from email.mime.text import MIMEText
import datetime
import time


# è®°å½•ä½ ä¿©å¥½äº†å¤šå°‘å¤©
def getDays():
    
    inlove_date=datetime.datetime(2019,9,12)
    today_date=datetime.datetime.today()
    inlove_days=(today_date-inlove_date).days
    return str(inlove_days)

# è·å–çŸ­æ–‡çš„ç½‘é¡µä¿¡æ¯
def getHTMLText(url,headers):
    try:
        r = requests.get(url,headers=headers,timeout=30)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text

    except:
        return "çˆ¬å–å¤±è´¥"

# ç”ŸæˆçŸ­æ–‡å†…å®¹
def parsehtml2(html):
    text=[]
    soup=BeautifulSoup(html,'html.parser')
    t=soup.find(attrs={'class':'jxa_content','id':'articlebody'})
    for i in t.findAll('p'):
        text.append(i.text)
    #print(text)
    return "\n".join(text)

def parsehtml(namelist,urllist,html):
    url='http://www.en8848.com.cn/'
    soup=BeautifulSoup(html,'html.parser')
    t=soup.find(attrs={'class':'ch_content'})
    #print(t)
    i=t.find_all('a')
    # print(i)
    # print(len(i))
    """å¯ä»¥å…ˆè¿›è¡Œå¦‚æ­¤æœç´¢ï¼Œå†æ ¹æ®æ˜¾ç¤ºæ‰€å¾—ï¼Œè¿›è¡Œç­›é€‰ï¼Œ
    for link in i:
        print(link.get('href'))
        print(link.get('title'))
    """
    for link in i[1:59:2]:
       urllist.append(url+link.get('href'))
       namelist.append(link.get('title'))

def sendemail(url,headers,title):
    date_today=time.strftime("%Y-%m-%d", time.localtime())
    msg_from='1152768760@qq.com'                                 #å‘é€æ–¹é‚®ç®±
    passwd='yfrplkgncgtkidga'                                   #å¡«å…¥å‘é€æ–¹é‚®ç®±çš„æˆæƒç 
    receivers=['1511180952@qq.com']             #æ”¶ä»¶äººé‚®ç®±
                            
    subject="Today's story from Laofei " +str(date_today)       #ä¸»é¢˜     
    html=getHTMLText(url,headers)
    content='Dear Jiangjiang:\n    We have been in love for '+getDays()+' Days !\n\nâ­â­â­â­â­â¤â¤ğŸ’—â¤â¤â­â­â­â­â­'+parsehtml2(html)                                        #æ­£æ–‡
    msg = MIMEText(content)
    msg['Subject'] = subject
    msg['From'] = msg_from
    msg['To'] = ','.join(receivers)
    try:
        s=smtplib.SMTP_SSL("smtp.qq.com",465)                   #é‚®ä»¶æœåŠ¡å™¨åŠç«¯å£å·
        s.login(msg_from, passwd)
        s.sendmail(msg_from, msg['To'].split(','), msg.as_string())
        print("å‘é€æˆåŠŸ")
    except:
        print("å‘é€å¤±è´¥")
    finally:
        s.quit()




def main():


    headers = {'User-Agent':'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50',
               }

    urllist=[]
    namelist=[]
    for i in range(1,21):
        if i==1:
            url='http://www.en8848.com.cn/article/love/dating/index.html'
        else:
            url='http://www.en8848.com.cn/article/love/dating/index_'+str(i)+'.html'
        print ("æ­£åœ¨çˆ¬å–ç¬¬%sé¡µçš„è‹±è¯­çŸ­æ–‡é“¾æ¥ï¼š" % (i))
        print (url+'\n')
        html=getHTMLText(url,headers)
        # print(html)
        parsehtml(namelist,urllist,html)
    
    #print("çˆ¬å–é“¾æ¥å®Œæˆ")
    date=int(getDays()) - 82
    #print(date)
    sendemail(urllist[date],headers,namelist[date])
    #print(len(namelist))
    #print(namelist[0])
    
    
    
if __name__=='__main__':
    main()

```
